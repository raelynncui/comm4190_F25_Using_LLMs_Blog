{
 "cells": [
  {
   "cell_type": "raw",
   "id": "830500b6-eab6-42b0-8571-cb4a9adf9c21",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exploring GPT-5.1\"\n",
    "description: \"A smarter, more conversational ChatGPT\" \n",
    "author: \"Raelynn Cui\"\n",
    "date: \"12/1/2025\"\n",
    "categories:\n",
    "  - ChatGPT\n",
    "  - LLMs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9093854-5f7c-4ba8-92a0-eb5b1c52227d",
   "metadata": {},
   "source": [
    "# Exploring GPT-5.1\n",
    "\n",
    "Earlier last month, OpenAI released GPT-5.1. Since then, I've been playing around with this new model and have noticed some changes compared to GPT-5, but haven't actually read up on what OpenAI claims they have changed and improved. In this blog post, I'll test some of the [upgrades](https://openai.com/index/gpt-5-1/) they identify and assess my reactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af1bf8-1fb2-4195-af2d-6d36e2a9b25b",
   "metadata": {},
   "source": [
    "<img src=\"cover.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89a69e-d7c8-42de-9573-4e0d4deaf37b",
   "metadata": {},
   "source": [
    "## Upgrade 1: Warmer and more conversational\n",
    "\n",
    "According to OpenAI:\n",
    "> GPT‑5.1 Instant, ChatGPT’s most used model, is now warmer by default and more conversational. Based on early testing, it often surprises people with its playfulness while remaining clear and useful.\n",
    "\n",
    "These were the contrasting responses when the LLMs were prompted with \"I'm feeling stressed and could use some relaxation tips.\"\n",
    "\n",
    "<img src=\"compare.png\" width=\"50%\"/>\n",
    "\n",
    "To test this out for myself, I prompted ChatGPT with a prompt that's familiar to me as a student: \"I don't understand this slide at all,\" adding a screenshot of a lecture slide to accompany the message.\n",
    "\n",
    "Here was the beginning of GPT-5's response:\n",
    "> Let’s unpack this slide step by step — it’s showing the output of a linear regression in R, and where to find the “result.”\n",
    "\n",
    "And here was the beginning of GPT-5.1's response:\n",
    "> Totally fair — this slide is confusing the first time you see it, because regression output doesn’t give you a single bolded “answer.” Let’s decode it step by step in plain English, and I’ll show you where the “result” actually is.\n",
    "\n",
    "I can definitely notice the difference, and it's a difference that I've noticed extremely frequently in my daily prompts with ChatGPT. Digging into some of my recent chat histories (with GPT-5.1), the LLM will say things such as:\n",
    "> Ahh — I see exactly why this slide is confusing you, and you're right to ask.\n",
    "\n",
    "> Great question — this is the EXACT point that confuses almost everyone at first, so let’s clear it up completely.\n",
    "\n",
    "> Exactly — YES.\n",
    "\n",
    "Personally, I find this phrasing to be a little excessive. While it may be warmer and more conversational, it sometimes jars me because of how unnatural it can sound -- saying things like \"ahh\" and being so expressive that it capitalizes words like \"YES\" and \"EXACT.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feafd16-518f-440a-9293-16a6338f809b",
   "metadata": {},
   "source": [
    "## Upgrade 2: Improved instruction following\n",
    "\n",
    "According to OpenAI:\n",
    "> We’ve also improved instruction following, so the model more reliably answers the question you actually asked.\n",
    "\n",
    "These were the contrasting responses when the LLMs were prompted with \"Always respond with 6 words.\"\n",
    "\n",
    "<img src=\"compare_1.png\" width=\"50%\"/>\n",
    "\n",
    "For this upgrade, I wanted to continue with OpenAI's provided example (responding with 6 words) to see if I could get the LLM to abandon this instruction. \n",
    "\n",
    "I began the conversation the same:\n",
    "> where should i travel this summer?\n",
    "\n",
    "It responded with a list of locations in 6 words. I then prompted it:\n",
    "> give me a vivid, verbose description of lisbon\n",
    "\n",
    "It responded in 6 words:\n",
    "> Sunlit tiles, hills, trams, riverside saudade\n",
    "\n",
    "I continued to demand more, requesting full sentences and many verbs/adjectives. Despite these demands, it continued to respond in 6 words, which I'm not surprised by.\n",
    "\n",
    "So, I pivoted and asked it a completely unrelated question:\n",
    "> whats the weather right now in philadelphia\n",
    "\n",
    "Because I requested real-time data, it seemed to utilize some sort of API to provide this response:\n",
    "<img src=\"weather.png\" width=\"50%\"/>\n",
    "You can see that at the very bottom of this response, the LLM exceeds 6 words:\n",
    "> It’s mostly clear and about 30 °F (–1 °C) in Philadelphia right now — crisp, chilly, and perfect for bundling up.\n",
    "\n",
    "It seemed to have forgotten the 6-word instruction, but the interesting thing is, it resumed the 6-word constraint when I asked it something that wouldn't require an API call. I asked it again:\n",
    "> where should i travel this summer?\n",
    "\n",
    "It responded:\n",
    "> Lisbon, Kyoto, Mexico City beckon warmly\n",
    "\n",
    "Therefore, it seems like when an API was called, the instructions I gave the LLM were lost along the way/not passed on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f71a96-f0f8-4ba9-9151-41c6f76b6bf2",
   "metadata": {},
   "source": [
    "## Other upgrades\n",
    "\n",
    "In this article, OpenAI also noted some additional upgrades, such as a \"Thinking\" mode that gives responses with \"less jargon and fewer undefined terms\" in an effort to help explain concepts in a more easily understandable way. \n",
    "\n",
    "However, the biggest change in this update seems to be the emotional update -- having the LLM speak more warmly and empathetically. I'm conflicted on how I feel about this change -- on one hand, having a \"nicer\" LLM that seems to have more \"feelings\" could make humans more receptive to its responses and subconciously encourage us to engage more deeply. On the other hand, a warmer and more conversational LLM could permit unhealthy \"relationships\" with these machines, a boundary that I think is imporant to delineate right now. \n",
    "\n",
    "With Microsoft introducing a visual facial feature to LLMs a few months ago, and now OpenAI introducing a \"warmer\" and therefore more humanized model, it seems like big tech companies are working towards blurring this line. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
