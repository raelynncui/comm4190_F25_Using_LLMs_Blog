{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3856cf34-787f-4af7-a5b2-af4df26ae76d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Book Reflection #2\"\n",
    "description: \"Ethan Mollick's 'Co-Intelligence: Living and Working with AI'\" \n",
    "author: \"Raelynn Cui\"\n",
    "date: \"10/6/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Book Reflection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665e6e4-b34f-4876-a8ce-21c0ec5a55b5",
   "metadata": {},
   "source": [
    "# Book Reflection #2: Co-Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0534ec-87d7-4cd7-ade5-7ee237c95dd2",
   "metadata": {},
   "source": [
    "<img src=\"cover.jpeg\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654bff7-0bf0-4fbc-9931-ec8a913c86d9",
   "metadata": {},
   "source": [
    "In this second book reflection on Ethan Mollick's *Co-Intelligence*, I'm going to talk about my thoughts on Mollick's \"Four Rules for Co-Intelligence.\" He presents these four rules in the first part of the book, laying out his opinion on how humans should function alongside AI.\n",
    "\n",
    "## Ethan Mollick’s Four Rules for Co-Intelligence\n",
    "\n",
    "> **1. Always invite AI to the table**  \n",
    "> **2. Be the human in the loop**  \n",
    "> **3. Treat AI like a person**  \n",
    "> **4. Assume this is the worst AI you will ever use**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89385d3a-ef82-4869-b1f5-7309db5f874e",
   "metadata": {},
   "source": [
    "<img src=\"four_principles.jpeg\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956568ef-2d4f-4c37-a1d5-2aa0c6de097c",
   "metadata": {},
   "source": [
    "### 1. Always invite AI to the table\n",
    "\n",
    "Mollick’s first rule is pretty simple. He says that we shouldn't just use AI when it's convenient, but intentionally include it in all areas of our lives, whether it be creative, analytical, etc.\n",
    "\n",
    "During this passage, Mollick kept referring to AI as an \"assistive tool.\" However, I felt like the word \"tool\" is too passive -- tools are things that we use, whereas \"co-intelligence\" feels like it should suggest something more reciprocal. If I were to \"invite AI to the table,\" it should be more like a peer who asks questions, points out blind spots, or generates ideas I wouldn’t have thought of alone -- not just act as a side tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5d42e-d01a-43e1-8d1a-8488e231a418",
   "metadata": {},
   "source": [
    "<img src=\"table.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86488ee-17c9-41da-b42f-74d3b9f3f108",
   "metadata": {},
   "source": [
    "### 2. Be the human in the loop\n",
    "\n",
    "Earlier this summer, I was chatting with someone who works in big pharma and their perspective on the growing calls for agentic AI solutions. During this conversation, they expressed their belief that pharma is an industry in which humans must remain in the loop (at least for now), since they're dealing with PII (Personally Identifiable Information) and extremely sensitive health data that could mean life or death.\n",
    "\n",
    "I was reminded of this conversation when I read this second rule, and it resonated with me because having a \"human in the loop\" is a great way to incorporate accountability. \n",
    "\n",
    "Mollick reframes it more as active participation (not completely supervising AI, but collaborating with it). I felt like there was a bit of a shift here, moving away from AI as just a tool and toward AI as a collaborative engine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beca117-d751-4c82-87d5-8ff75ed7711e",
   "metadata": {},
   "source": [
    "### 3. Treat AI like a person\n",
    "\n",
    "This title definitely took me by surprise at first and I was initially quick to disagree -- the dangers of humans perceiving a machine as truly human immediately came into mind. For example, I recently saw that Microsoft launched a feature that added a face to Copilot. Not only can Copilot talk in very human-like ways, but it now has a face that can convey another dimension of emotion. While I think this feature is really cool, this illusion of a \"person\" behind the machine could have some negative psychological impacts and deals with a fine line that could be crossed.\n",
    "\n",
    "However, Mollick actually acknowledges the dangers of anthropomorphizing AI. He's not promoting a delusional mindset of treating an LLM like a person, but rather promoting the idea that treating an LLM like a person makes interacting with it easier, since humans are more naturally wired for dialogue, creativity, and empathy.\n",
    "\n",
    "In this passage, Mollick says that \"working with AI is easiest if you think of it like an alien person rather than a human-built machine.\" I agree with this and really like this way of looking at it -- with a machine, you have clear inputs and outputs. You know that when you pass a value x into a function, you'll get y. However, most people don't have this level of understanding to understand AI like this -- we aren't able to say for certain what the machine will output when we input x. Therefore, viewing it as more of an \"alien mind\" is a creative and practical way of thinking about it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e3f6ba-db79-4c01-8403-4f5de4fdd274",
   "metadata": {},
   "source": [
    "![*Microsoft's new Copilot interface, which features an expressive and anthropomorphized face*](copilot.png){fig-align=\"center\" width=\"80%\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32b840-14ef-424f-8898-17b79b135eb2",
   "metadata": {},
   "source": [
    "### 4. Assume this is the worst AI you will ever use\n",
    "\n",
    "In this passage, Mollick talks about the rapid pace of advancement in AI, acknowledging how quickly models have been improving. I related to this final rule a lot -- the difference in quality and capability of LLMs from now compared to when I started using them is incredible to think about. \n",
    "\n",
    "However, I wonder if this rate of progress will plateau in the near future. From my personal experience, the jump from GPT-3 to GPT-4/GPT-4o was extremely significant, whereas the jump to GPT-5 hasn't been as striking. While this is just my personal experience, I've noticed some people online feeling a similar way.\n",
    "\n",
    "Either way, I think that this rule points to a larger call for experimentation and adaptation. As AI evolves, humans must be flexible and agile in adapting alongside it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
