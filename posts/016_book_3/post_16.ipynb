{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4f9a94db-3082-421c-adc1-98cadd32343d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Book Reflection #3\"\n",
    "description: \"Recent News: AI-Generated Errors in Deloitte's Report to the Australian Government\" \n",
    "author: \"Raelynn Cui\"\n",
    "date: \"10/16/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Professional\n",
    "  - Book Reflection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1310f8-34cc-44ea-888c-6fb692ebb0b4",
   "metadata": {},
   "source": [
    "# Book Reflection #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960f2f0-4999-49dd-a58b-99c81612c47d",
   "metadata": {},
   "source": [
    "<img src=\"cover.jpeg\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37fa17-0155-4654-9633-0439ad41eda7",
   "metadata": {},
   "source": [
    "In Chapter 5, “AI As a Creative,” Mollick discusses how LLMs can hallucinate and make up false information:\n",
    "\n",
    "> “The biggest issue limiting AI is also one of its strengths: its notorious ability to make stuff up, to hallucinate… Hallucinations sound likely and contextually appropriate enough to make it hard to tell lies from the truth.” (Mollick, 93-94)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd56dc-b9d8-4ed9-bfcf-96639b067033",
   "metadata": {},
   "source": [
    "This reminded me of recent news that I saw trending on social media -- Deloitte was caught producing a report for the Australian government that included AI-generated hallucinations. In this blog post, I’ll summarize these recent events and talk through some of my opinions on what this scandal implies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57567506-65a4-466b-b96f-e53cbc6c501a",
   "metadata": {},
   "source": [
    "<img src=\"deloitte.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766a0fd-5576-4aec-a00d-0cc42aa30489",
   "metadata": {},
   "source": [
    "## The Deloitte Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23144a60-2396-48fd-9869-23851fedd612",
   "metadata": {},
   "source": [
    "This report by Deloitte was originally published on the Australian government’s Department of Employment and Workplace Relations website. This report was found to contain numerous AI-generated errors, such as “a fabricated quote from a federal court judgment and references to nonexistent academic research papers,” says AP News. \n",
    "\n",
    "Some of these errors were initially discovered by Chris Rudge, a researcher at Sydney University, who noticed these fabricated references. He found up to 20 errors at first, which included a completely made-up book title attributed to a peer at Sydney University, Lisa Burton Crawford. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dcd1ba-ac89-4bcb-9643-4860b1959f10",
   "metadata": {},
   "source": [
    "<img src=\"rudge.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb4208-dabd-4829-8d2d-03fa1d7b264c",
   "metadata": {},
   "source": [
    "Since then, Deloitte has agreed to refund $290,000 to the Austrian government for these errors. The company claims that “the updates made in no way impact or affect the substantive content, findings and recommendations in the report.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c19b5-80e8-48a1-87d0-b5ebd62bdc18",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Overall, these mistakes seemed extremely reckless and easily preventable. In my opinion, using LLMs to generate research ideas and sources could be a great starting point, but it’s the bare minimum for the researcher to validate these sources and findings. Not doing so creates a negative snowball effect – not only does the burden fall on other citizens (such as Rudge, in this case) to examine the legitimacy of these reports, but it ultimately creates an air of suspicion that delays progress and real solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e744130-d0c5-4d71-9e42-42462fa16129",
   "metadata": {},
   "source": [
    "<img src=\"workplace.jpg\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ede25f-92c3-47d7-a3f3-71fbf15940bb",
   "metadata": {},
   "source": [
    "According to a CFO Dive article, “Nearly six out of 10 employees admit to making mistakes in their work due to AI errors, according to a KPMG study released in April. In addition, about half use AI in the workplace without knowing whether it’s allowed and more than four in 10 are ‘knowingly using it improperly’ at work, the study found.” I think that this points toward a need for better AI education in the workplace, especially when it's informing real-life decisions such as this case with the Australian government. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
