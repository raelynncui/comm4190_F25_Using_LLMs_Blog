{
 "cells": [
  {
   "cell_type": "raw",
   "id": "419924ee-d695-4207-a6c6-b454c447582b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Endless Image Replication\"\n",
    "description: \"What happens when you tell an image generation model to repeatedly replicate an image?\" \n",
    "author: \"Raelynn Cui\"\n",
    "date: \"9/9/2025\"\n",
    "categories:\n",
    "  - ChatGPT\n",
    "  - Image Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a36d0-b6c9-4a57-9e6b-325287fe5f07",
   "metadata": {},
   "source": [
    "# Endless Image Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4740bc-1e0c-4c7b-83bb-93d2eb8be8e7",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "In this blog, I play around with OpenAI's GPT-5 image generation capabilities. Beginning with a photo of my dog, I repeatedly give the prompt *\"create a replica of this image. don't change a thing\"*, feeding the output of each iteration as the input of the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf92b36-8bb3-4fb8-98e7-5a46f1fedf79",
   "metadata": {},
   "source": [
    "<img src=\"blog_cover.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf2f10-d364-468a-a839-632d093c6369",
   "metadata": {},
   "source": [
    "I was inspired by this [Reddit post](https://www.reddit.com/r/ChatGPT/comments/1n8dung/chatgpt_prompted_to_create_the_exact_replica_of/), where a user shows how an image of a person became completely unrecognizable after the 74th iteration! My experiment didn't go that far though, yielding different (and a little more underwhelming) results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d75436b-63b6-4bfb-bbf6-2fd039bc033f",
   "metadata": {},
   "source": [
    "<img src=\"reddit.gif\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8e66e-5025-49ed-89a5-58af0f0b4842",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84935e67-6992-4c77-96ee-f0cceacf1350",
   "metadata": {},
   "source": [
    "I performed 11 iterations of the prompt using the GPT-5 model. Here's an animation of my results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55d54b-53c4-466c-b982-21017befb164",
   "metadata": {},
   "source": [
    "<img src=\"dogresult.gif\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3be5a5-3f16-4334-bffe-9862f46d6ccb",
   "metadata": {},
   "source": [
    "The first iteration was extremely good -- the original image is on the left and the output is on the right. I initially had high hopes, since there are no noticeable differences I can spot when seeing the images side by side. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d12939-1949-4eba-acfd-d4cde639a59e",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: flex-start; margin: 20px 0;\">\n",
    "  <!-- First image + caption -->\n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; margin-right: 28px; text-align: center;\">\n",
    "    <img src=\"1.JPG\" alt=\"Original image\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "\n",
    "  <!-- Second image + caption -->\n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; text-align: center;\">\n",
    "    <img src=\"2.png\" alt=\"First output\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb540ce-0bfd-41e3-b6e5-b9e533a4e003",
   "metadata": {},
   "source": [
    "However, it went quickly downhill after that. The biggest jump seemed to be within the third and fourth images, where the fourth image suddenly gained lots of noise and a higher contrast/sharpness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b2279-bd0e-40b2-85c1-2ea519ebdf56",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: flex-start; margin: 20px 0;\">\n",
    "  <!-- First image + caption -->\n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; margin-right: 28px; text-align: center;\">\n",
    "    <img src=\"3.png\" alt=\"Third image\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "\n",
    "  <!-- Second image + caption -->\n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; text-align: center;\">\n",
    "    <img src=\"4.png\" alt=\"Fourth image\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62352349-e340-4dc2-aba5-6fea812e213e",
   "metadata": {},
   "source": [
    "After that, it seemed to hit a plateau where the image became black and white and extremely noisy, with the outline of my dog still slightly distinguishable. This was the final photo after 11 rounds:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32648fb8-0369-494e-9050-1a28b8cf799d",
   "metadata": {},
   "source": [
    "<figure style=\"margin: 0; flex: 0 0 auto; margin-right: 28px; text-align: center;\">\n",
    "    <img src=\"11.png\" alt=\"Final image\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5503324-e442-404e-ba70-d4f62d880684",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "I couldn't find any detailed and definitive source online regarding how the GPT-5 model generates images, but I'm assuming what happened here is that some noise/mismatches got introduced at some stage, which then got amplified as the iterations continued. According to an article on [The Verge](https://www.theverge.com/openai/635118/chatgpt-sora-ai-image-generation-chatgpt), the GPT-4o model uses an autoregressive approach (not diffusion), where it generates an image token by token, just like text. Instead of starting with random noise, like with diffusion, it predicts a sequence of image tokens that make up the image. Because of this, I'm surprised that the model introduced so much static/noise and didn't veer off the path like the Reddit example. \n",
    "\n",
    "In fact, I even fed the final image into GPT-5 and asked if it could identify what it was. It said: \"This is an image of a dog lying in the grass. The photo appears to have been processed with a strong filter or edge-detection effect, which makes it look like a high-contrast sketch or engraving. You can still make out the dogâ€™s head, body, and the surrounding grass and trees in the background, though the details are stylized.\" Therefore, it's puzzling as to why it didn't retain a more obvious \"dog token\" in its image generation process. \n",
    "\n",
    "To push the model a bit further, I asked it to \"generate an image of what you think the original photo looked like.\" This was what it generated -- pretty good!\n",
    "\n",
    "(From left to right: the original image, the final image, and the reconstructed image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22e459-c9da-4a4b-a3f6-0f2fea5ae8fa",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: flex-start; margin: 20px 0;\">\n",
    "  \n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; margin-right: 28px; text-align: center;\">\n",
    "    <img src=\"1.JPG\" alt=\"Original image\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "\n",
    "  \n",
    "  <figure style=\"margin: 0; flex: 0 0 auto; margin-right: 28px; text-align: center;\">\n",
    "    <img src=\"11.png\" alt=\"Last output\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "\n",
    "   <figure style=\"margin: 0; flex: 0 0 auto; text-align: center;\">\n",
    "    <img src=\"gptreconstruction.png\" alt=\"Reconstructed output\"\n",
    "         style=\"display: block; height: 400px; width: auto; border-radius: 8px;\">\n",
    "  </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72906f6c-6fcd-4752-8a06-5715dd3e65fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
