{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0ae6ee3e-c84a-4321-98e3-7da50553f1cb",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Book Reflection #5\"\n",
    "description: \"Mollick's Paths for the Future of AI\" \n",
    "author: \"Raelynn Cui\"\n",
    "date: \"12/4/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Book Reflection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e3f83-b02e-489d-acad-3d0851fbff2e",
   "metadata": {},
   "source": [
    "# Book Reflection #5\n",
    "\n",
    "<img src=\"cover.jpeg\" width=\"100%\"/>\n",
    "\n",
    "Toward the end of Co-Intelligence, Mollick lays out a few different paths that he thinks AI could take in the future, addressing the implications of them and what he thinks the world would look like if we went down each of these paths. In this blog post, I'll reflect on each of these paths and Mollick's overall framework. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444d459-26bf-4540-a375-5906955f19f2",
   "metadata": {},
   "source": [
    "## The four paths\n",
    "\n",
    "Mollick explains each of the paths he thinks AI could take in words (with no diagrams), so I thought it would be helpful to have a visual map of his argument. I made this simple map to visualize these paths:\n",
    "\n",
    "<img src=\"ai_future.png\" width=\"80%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3fc49d-3d36-4833-8ac0-4b7f48609be6",
   "metadata": {},
   "source": [
    "Beginning from now, he believes there are four mutually exclusive paths we could take: either AI stops improving and its current state is as good as it will get, AI continues to improve but will eventually plateau, AI improves exponentially, or the most extreme case, we achieve some form of AGI/sentience. \n",
    "\n",
    "Although Mollick is certaintly a \"pro-AI\" figure, I think that even he wouldn't be quick to say that this fourth path (AGI/sentience) is for certain -- he seems to align much more with the 3rd or even 2nd path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b72bf-f8c4-44d5-878f-846526ca7891",
   "metadata": {},
   "source": [
    "## Path 1: AI stops improving\n",
    "\n",
    "If we go down this path, AI stops improving at our current moment in time and \"now is as good as it gets.\" Since Mollick has written this book, we can see that this isn't completely true -- OpenAI, for example, has recently released GPT-5, Sora has been released, and so on. While the marginal difference in machine capabilities of these new innovations can be debated, I think they undoubtedly have shown *some* form of improvement. \n",
    "\n",
    "<img src=\"sora.png\" width=\"40%\"/>\n",
    "\n",
    "Even if AI stops improving at our given moment in time, Mollick argues that AI existing in and of itself will have consequences that we still have to grapple with -- specifically regarding our relationship with information, which AI has changed dramatically. He believes that our relationship with information could change in one of three ways:\n",
    "1. Because AI-generated information is harder to detect, we will rely more on mainstream media sources to \"arbitrate\" what's real and what's not.\n",
    "2. AI-generated information only serves to reinforce our biases and current beliefs, making us more ignorant and entrenched in our own echo-chambers (more than we currently are with the structure of the internet).\n",
    "3. We become fatigued with all of this fake, AI-generated information and turn away from online sources.\n",
    "\n",
    "Out of all three of these consequences, I think that the second is the most likely in the short term. Long-term, however, I'm hoping that this isn't the case, and I could see the first or third consequence emerging more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140e42d-9f70-4590-8a47-5a0e1d24dbf2",
   "metadata": {},
   "source": [
    "## Path 2: AI improves slowly\n",
    "\n",
    "If we go down this path, it seems like AI will eventually plateau in its progress. There's already evidence of this -- looking at the bar chart below, you can see that performance increases of OpenAI's model have marginally decreased over time when evaluated with the MMLU(Massive Multitask Language Understanding), a \"benchmark is a standardized test used to evaluate the knowledge and reasoning capabilities of artificial intelligence (AI) language models across a wide range of subjects.\" \n",
    "\n",
    "<img src=\"mmlu.png\" width=\"40%\"/>\n",
    "\n",
    "Mollick calls this path a \"good outcome,\" since it keeps humans in the loop and will allow us to leverage benefits of AI responsibly. \n",
    "\n",
    "Personally, I think that this path is the most likely and aligns most with what I've experienced as a more casual (non-enterprise) user of AI. Recently, I've even found myself reverting back to older models of ChatGPT (4o) instead of GPT-5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb8067-b2d7-45de-b54e-6ed5b8dbad2a",
   "metadata": {},
   "source": [
    "## Path 3: AI improves exponentially\n",
    "\n",
    "While I agree most with path 2, I could also see humanity going down this path as well. While researching online, I found some sources talking about how innovations often follow an S-curve: \"an almost undetectable buildup of knowledge and craft is met with a spark, resulting in an explosion of innovation, and eventually reaching a plateau.\" \n",
    "\n",
    "<img src=\"innovation.png\" width=\"40%\"/>\n",
    "\n",
    "Many who believe that AI is similarly following an S-curve also believe that the next phase of innovation (and next S-curve) will be kicked off with the use of propriety business data in AI: \"workplace data is of far higher quality than whatâ€™s left of public data for training purposes, especially compared to running the dregs of the internet through the transformer mill. (The results of which may be why a lot of AI-generated content is already being called 'slop.').\" I know that many companies are already integrating AI with their proprietary data, but I'm assuming that much of this information is not revelaed to the public.\n",
    "\n",
    "Compared to the second path, this path will restructure society and the way we think about things more significantly. It will require us to reconstruct the meaning of many things, such as the meaning of work and efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8794629c-2d81-49d8-801d-4a72c2fd9447",
   "metadata": {},
   "source": [
    "## Path 4: AGI/machine sentience\n",
    "\n",
    "If we go down this path, Mollick thinks the implications are straightforward -- \"human supremacy ends.\" I'm extremely skeptical of us going down this path, but I've even encountered a professor at Penn who strongly believes that AGI certainly already exists -- we just don't know about it. \n",
    "\n",
    "Additionally, I think this view could be shared by both \"doomers\" and \"zoomers,\" with the former viewing this path as a devastation and the latter viewing this path as the beginning of something new and extraordinary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
